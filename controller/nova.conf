[DEFAULT]
#quota_cores=25
reserved_host_memory_mb = 0
ram_allocation_ratio = 1.0
cpu_allocation_ratio=2.0
verbose=True
allow_resize_to_same_host=True
rootwrap_config=/etc/nova/rootwrap.conf
s3_host=CTRL_IP
s3_port=3333
osapi_compute_listen = 0.0.0.0
metadata_listen = 0.0.0.0
my_ip=CTRL_IP
instance_name_template=instance-%08x
image_service=nova.image.glance.GlanceImageService
enabled_apis=osapi_compute,metadata
cinder_endpoint_template=http://CTRL_IP:8776/v1/%(project_id)s
state_path=/opt/stack/data/nova
instances_path=/opt/stack/data/nova/instances
logging_context_format_string=%(asctime)s %(color)s%(levelname)s %(name)s [[01;36m%(request_id)s [00;36m%(user_name)s %(project_name)s%(color)s] [01;35m%(instance)s%(color)s%(message)s[00m
logging_default_format_string=%(asctime)s %(color)s%(levelname)s %(name)s [[00;36m-%(color)s] [01;35m%(instance)s%(color)s%(message)s[00m
logging_debug_format_suffix=[00;33mfrom (pid=%(process)d) %(funcName)s %(pathname)s:%(lineno)d[00m
logging_exception_prefix=%(color)s%(asctime)s TRACE %(name)s [01;35m%(instance)s[00m
ec2_dmz_host=CTRL_IP
transport_url = rabbit://guest:RABBITPW@CTRL_IP:5672/
compute_driver=libvirt.LibvirtDriver
resume_guests_state_on_host_boot=true
use_cow_images=true
running_deleted_instance_action=reap
running_deleted_instance_poll_interval=5
running_deleted_instance_timeout=120
rescue_timeout=0
reboot_timeout=0
instance_usage_audit_period=hour
instance_usage_audit=True
metadata_workers=2
osapi_compute_workers=2
debug=True
network_api_class=nova.network.neutronv2.api.API
vif_plugging_is_fatal=False
vif_plugging_timeout=0
use_rootwrap_daemon = True

# FOR PCI PASSTHROUGH (IF REGION HAS COMPUTE NODES TO SUPPORT IT)
#[pci]
#alias = {"vendor_id":"10de", "product_id":"1091", "name":"a1"}
#passthrough_whitelist =

[neutron]
service_metadata_proxy = True
endpoint_override = http://CTRL_IP:9696
region_name = REGION_NAME
auth_strategy = keystone
#project_domain_name = Default
#user_domain_name = Default
project_name = service
password = SERVICEPW
username = neutron
auth_url = http://iam.savitestbed.ca:35357/v2.0/
auth_type = password
service_metadata_proxy=True
default_floating_pool=ext-net

[libvirt]
cpu_mode = none
virt_type = kvm
use_virtio_for_bridges=True
wait_soft_reboot_seconds=60

[vnc]
enabled = True
novncproxy_base_url=http://CTRL_IP:6080/vnc_auto.html
xvpvncproxy_base_url=http://CTRL_IP:6081/console
server_listen=CTRL_IP
server_proxyclient_address=CTRL_IP

[glance]
api_servers = http://CTRL_IP:9292
debug = True

[database]
connection=mysql+pymysql://root:MYSQLPW@CTRL_IP/nova?charset=utf8

[api_database]
connection=mysql+pymysql://root:MYSQLPW@CTRL_IP/nova_api?charset=utf8

[osapi_v3]
enabled = False

[keystone_authtoken]
memcached_servers = 127.0.0.1:11211
region_name = REGION_NAME
auth_type = password
username = nova
password = SERVICEPW
project_name = service
auth_url = http://iam.savitestbed.ca:35357/v2.0

[spice]
enabled = false
html5proxy_base_url = http://CTRL_IP:6082/spice_auto.html


[ironic]
api_endpoint = http://CTRL_IP:6385/v1
project_name = service
auth_region = REGION_NAME
auth_url = http://iam.savitestbed.ca:35357/v2.0
password = ironicpass
username = ironic

[upgrade_levels]
# Set a version cap for messages sent to compute services. If
# you plan to do a live upgrade from havana to icehouse, you
# should set this option to "icehouse-compat" before beginning
# the live upgrade procedure. (string value)
#compute=kilo
#network=kilo

[filter_scheduler]
scheduler_default_filters=ComputeFilter,AvailabilityZoneFilter,ComputeCapabilitiesFilter,ImagePropertiesFilter

[placement]
auth_type = password
username = placement
password = SERVICEPW
auth_url = http://iam.savitestbed.ca:35357/v2.0
project_name = service
region_name = REGION_NAME

[notifications]
notify_on_state_change=vm_and_task_state

[oslo_concurrency]
lock_path=/opt/stack/data/nova

